{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b81b7a67",
   "metadata": {},
   "source": [
    "## extrat_chunks_json 변환 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a4385c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdfplumber\n",
    "import re\n",
    "import json\n",
    "from typing import List, Dict\n",
    "\n",
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    \"\"\"PDF 파일에서 전체 텍스트 추출\"\"\"\n",
    "    text = \"\"\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            page_text = page.extract_text()\n",
    "            if page_text:\n",
    "                text += \"\\n\" + page_text\n",
    "    return text\n",
    "\n",
    "def chunk_grammar_rules(text: str) -> List[Dict]:\n",
    "    \"\"\"어문 규범 문서를 규칙 단위로 청킹\"\"\"\n",
    "    chunks = []\n",
    "    pattern = r\"<([^>]+)>\"\n",
    "    split_parts = re.split(pattern, text)\n",
    "    for i in range(1, len(split_parts), 2):\n",
    "        title = split_parts[i].strip()\n",
    "        content = split_parts[i + 1].strip()\n",
    "\n",
    "        category = title.split(\" - \")[0].strip()\n",
    "        rule_number_match = re.search(r\"제\\d+항\", title)\n",
    "        rule_number = rule_number_match.group() if rule_number_match else None\n",
    "\n",
    "        examples = re.findall(r\"^- (.+)\", content, flags=re.MULTILINE)\n",
    "        notes =  re.findall(r\"((?:\\[붙임 \\d+\\]|다만)[\\s\\S]+?)(?=\\[붙임|\\Z)\", content)\n",
    "        pairs = re.findall(r\"ㄱ: (.+?)\\n\\s*ㄴ: (.+)\", content, flags=re.DOTALL)\n",
    "\n",
    "        first_line = content.split(\"\\n\")[0]\n",
    "        main_rule = first_line.strip()\n",
    "\n",
    "        chunks.append({\n",
    "            \"title\": title,\n",
    "            \"category\": category,\n",
    "            \"rule_number\": rule_number,\n",
    "            \"main_rule\": main_rule,\n",
    "            \"examples\": examples,\n",
    "            \"notes\": [note.strip() for note in notes],\n",
    "            \"pairs\": [{\"correct\": g.strip(), \"wrong\": n.strip()} for g, n in pairs],\n",
    "            \"source\": \"국어 지식 기반 생성(RAG) 참조 문서\"\n",
    "        })\n",
    "    return chunks\n",
    "\n",
    "def main():\n",
    "    pdf_path = \"/home/jiin/korean_grammar_rag/data/document.pdf\"\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    chunks = chunk_grammar_rules(text)\n",
    "\n",
    "    # 4. JSON으로 저장\n",
    "    output_path = \"korean_grammar_chunks.json\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(chunks, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    print(f\"[✔] 총 {len(chunks)}개의 규칙이 {output_path}에 저장되었습니다.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9249a104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 청크 수: 115\n",
      "\n",
      "첫 번째 청크 구조:\n",
      "{\n",
      "  \"title\": \"띄어쓰기 - 한글 맞춤법 제43항\",\n",
      "  \"category\": \"띄어쓰기\",\n",
      "  \"rule_number\": \"제43항\",\n",
      "  \"main_rule\": \"단위를 나타내는 명사는 띄어 쓴다.\",\n",
      "  \"examples\": [\n",
      "    \"한 개, 차 한 대, 금 서 돈, 소 한 마리, 옷 한 벌, 열 살, 조기 한 손, 연필 한 자루, 버\",\n",
      "    \"두시 삼십분 오초, 제일과, 삼학년, 육층, 1446년 10월 9일, 2대대, 16동 502호, 제1실습\"\n",
      "  ],\n",
      "  \"notes\": [\n",
      "    \"다만, 순서를 나타내는 경우나 숫자와 어울려 쓰이는 경우에는 붙여 쓸 수 있다.\\n- 두시 삼십분 오초, 제일과, 삼학년, 육층, 1446년 10월 9일, 2대대, 16동 502호, 제1실습\\n실, 80원, 10개, 7미터\"\n",
      "  ],\n",
      "  \"pairs\": [],\n",
      "  \"source\": \"국어 지식 기반 생성(RAG) 참조 문서\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 청킹 결과 확인\n",
    "\n",
    "with open(\"/home/jiin/korean_grammar_rag/code/korean_grammar_chunks.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    chunks = json.load(f)\n",
    "\n",
    "print(f\"총 청크 수: {len(chunks)}\")\n",
    "print(\"\\n첫 번째 청크 구조:\")\n",
    "print(json.dumps(chunks[3], ensure_ascii=False, indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f97a9b",
   "metadata": {},
   "source": [
    "## 임베딩 후 벡터 저장소 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d018323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# 사용 예시\\ndef main():\\n    # RAG 시스템 초기화\\n    rag = SimpleKoreanRAG()\\n    \\n    # 청크 로드\\n    rag.load_chunks(\"korean_grammar_chunks.json\")\\n    \\n    # 임베딩 생성\\n    rag.create_embeddings()\\n    \\n    # 벡터 저장소 구축\\n    rag.build_vector_store()\\n    \\n    # 저장\\n    rag.save(\"./rag_system\")\\n    \\n    # 테스트 검색\\n    print(\"\\n=== 검색 테스트 ===\")\\n    test_queries = [\\n        \"먹이양 먹이량\",\\n        \"바래요 바라요\", \\n        \"띄어쓰기\",\\n        \"두음법칙\"\\n    ]\\n    \\n    for query in test_queries:\\n        print(f\"\\n🔍 쿼리: \\'{query}\\'\")\\n        results = rag.search(query, top_k=3)\\n        \\n        for i, (chunk, score) in enumerate(results):\\n            print(f\"  {i+1}. [{score:.3f}] {chunk[\\'title\\']}\")\\n            print(f\"     규칙: {chunk[\\'main_rule\\']}\")\\n\\nif __name__ == \"__main__\":\\n    main()'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import faiss\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class SimpleKoreanRAG:\n",
    "    def __init__(self):\n",
    "        \"\"\"간단한 한국어 RAG 시스템 초기화\"\"\"\n",
    "        print(\"한국어 임베딩 모델 로드 중...\")\n",
    "        \n",
    "        # 한국어 특화 임베딩 모델 로드\n",
    "        self.model = SentenceTransformer('jhgan/ko-sroberta-multitask')\n",
    "        \n",
    "        # GPU 사용 가능하면 GPU로\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model.to(device)\n",
    "        print(f\"사용 디바이스: {device}\")\n",
    "        \n",
    "        self.chunks = []\n",
    "        self.embeddings = None\n",
    "        self.index = None\n",
    "    \n",
    "    def load_chunks(self, json_path: str):\n",
    "        \"\"\"청크 데이터 로드\"\"\"\n",
    "        with open(json_path, 'r', encoding='utf-8') as f:\n",
    "            self.chunks = json.load(f)\n",
    "        print(f\"청크 로드 완료: {len(self.chunks)}개\")\n",
    "    \n",
    "    def create_text_for_embedding(self, chunk: Dict) -> str:\n",
    "        \"\"\"각 청크를 임베딩용 텍스트로 변환\"\"\"\n",
    "        # 기본 정보\n",
    "        title = chunk.get('title', '')\n",
    "        category = chunk.get('category', '')\n",
    "        main_rule = chunk.get('main_rule', '')\n",
    "        \n",
    "        # 예시들 합치기\n",
    "        examples = chunk.get('examples', [])\n",
    "        examples_text = ' '.join(examples) if examples else ''\n",
    "        \n",
    "        # 주의사항들 합치기  \n",
    "        notes = chunk.get('notes', [])\n",
    "        notes_text = ' '.join(notes) if notes else ''\n",
    "        \n",
    "        # 올바른/틀린 쌍들 합치기\n",
    "        pairs = chunk.get('pairs', [])\n",
    "        pairs_text = ''\n",
    "        for pair in pairs:\n",
    "            correct = pair.get('correct', '')\n",
    "            wrong = pair.get('wrong', '')\n",
    "            pairs_text += f' {correct} {wrong}'\n",
    "        \n",
    "        # 모든 텍스트 합치기\n",
    "        full_text = f\"{title} {category} {main_rule} {examples_text} {notes_text} {pairs_text}\"\n",
    "        return full_text.strip()\n",
    "    \n",
    "    def create_embeddings(self):\n",
    "        \"\"\"모든 청크의 임베딩 생성\"\"\"\n",
    "        print(\"임베딩 생성 중...\")\n",
    "        \n",
    "        # 각 청크를 텍스트로 변환\n",
    "        texts = []\n",
    "        for i, chunk in enumerate(self.chunks):\n",
    "            text = self.create_text_for_embedding(chunk)\n",
    "            texts.append(text)\n",
    "            \n",
    "            # 처음 3개만 확인용 출력\n",
    "            if i < 3:\n",
    "                print(f\"\\n청크 {i+1} 텍스트 샘플:\")\n",
    "                print(text[:200] + \"...\")\n",
    "        \n",
    "        # 임베딩 생성\n",
    "        self.embeddings = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"임베딩 생성 완료: {self.embeddings.shape}\")\n",
    "        \n",
    "        return self.embeddings\n",
    "    \n",
    "    def build_vector_store(self):\n",
    "        \"\"\"FAISS 벡터 저장소 구축\"\"\"\n",
    "        if self.embeddings is None:\n",
    "            raise ValueError(\"먼저 임베딩을 생성해주세요\")\n",
    "        \n",
    "        print(\"벡터 저장소 구축 중...\")\n",
    "        \n",
    "        # 임베딩 차원\n",
    "        dim = self.embeddings.shape[1]\n",
    "        print(f\"벡터 차원: {dim}\")\n",
    "        \n",
    "        # FAISS 인덱스 생성 (코사인 유사도용)\n",
    "        self.index = faiss.IndexFlatIP(dim)\n",
    "        \n",
    "        # 임베딩 정규화 (코사인 유사도를 위해)\n",
    "        embeddings_normalized = self.embeddings.copy().astype('float32')\n",
    "        faiss.normalize_L2(embeddings_normalized)\n",
    "        \n",
    "        # 벡터 추가\n",
    "        self.index.add(embeddings_normalized)\n",
    "        \n",
    "        print(f\"벡터 저장소 구축 완료: {self.index.ntotal}개 벡터\")\n",
    "    \n",
    "    def search(self, query: str, top_k: int = 5) -> List[Tuple[Dict, float]]:\n",
    "        \"\"\"쿼리로 유사한 청크 검색\"\"\"\n",
    "        if self.index is None:\n",
    "            raise ValueError(\"먼저 벡터 저장소를 구축해주세요\")\n",
    "        \n",
    "        # 쿼리 임베딩 생성\n",
    "        query_embedding = self.model.encode([query]).astype('float32')\n",
    "        faiss.normalize_L2(query_embedding)\n",
    "        \n",
    "        # 검색 수행\n",
    "        scores, indices = self.index.search(query_embedding, top_k)\n",
    "        \n",
    "        # 결과 반환\n",
    "        results = []\n",
    "        for score, idx in zip(scores[0], indices[0]):\n",
    "            if idx < len(self.chunks):\n",
    "                chunk = self.chunks[idx]\n",
    "                results.append((chunk, float(score)))\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def save(self, save_dir: str = \"./rag_system\"):\n",
    "        \"\"\"시스템 저장\"\"\"\n",
    "        import os\n",
    "        os.makedirs(save_dir, exist_ok=True)\n",
    "        \n",
    "        # 청크 저장\n",
    "        with open(f\"{save_dir}/chunks.json\", 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.chunks, f, ensure_ascii=False, indent=2)\n",
    "        \n",
    "        # 임베딩 저장\n",
    "        np.save(f\"{save_dir}/embeddings.npy\", self.embeddings)\n",
    "        \n",
    "        # FAISS 인덱스 저장\n",
    "        faiss.write_index(self.index, f\"{save_dir}/index.faiss\")\n",
    "        \n",
    "        print(f\"시스템이 {save_dir}에 저장되었습니다\")\n",
    "    \n",
    "    def load(self, save_dir: str = \"./rag_system\"):\n",
    "        \"\"\"저장된 시스템 로드\"\"\"\n",
    "        # 청크 로드\n",
    "        with open(f\"{save_dir}/chunks.json\", 'r', encoding='utf-8') as f:\n",
    "            self.chunks = json.load(f)\n",
    "        \n",
    "        # 임베딩 로드\n",
    "        self.embeddings = np.load(f\"{save_dir}/embeddings.npy\")\n",
    "        \n",
    "        # FAISS 인덱스 로드\n",
    "        self.index = faiss.read_index(f\"{save_dir}/index.faiss\")\n",
    "        \n",
    "        print(f\"시스템이 {save_dir}에서 로드되었습니다\")\n",
    "\n",
    "'''# 사용 예시\n",
    "def main():\n",
    "    # RAG 시스템 초기화\n",
    "    rag = SimpleKoreanRAG()\n",
    "    \n",
    "    # 청크 로드\n",
    "    rag.load_chunks(\"korean_grammar_chunks.json\")\n",
    "    \n",
    "    # 임베딩 생성\n",
    "    rag.create_embeddings()\n",
    "    \n",
    "    # 벡터 저장소 구축\n",
    "    rag.build_vector_store()\n",
    "    \n",
    "    # 저장\n",
    "    rag.save(\"./rag_system\")\n",
    "    \n",
    "    # 테스트 검색\n",
    "    print(\"\\n=== 검색 테스트 ===\")\n",
    "    test_queries = [\n",
    "        \"먹이양 먹이량\",\n",
    "        \"바래요 바라요\", \n",
    "        \"띄어쓰기\",\n",
    "        \"두음법칙\"\n",
    "    ]\n",
    "    \n",
    "    for query in test_queries:\n",
    "        print(f\"\\n🔍 쿼리: '{query}'\")\n",
    "        results = rag.search(query, top_k=3)\n",
    "        \n",
    "        for i, (chunk, score) in enumerate(results):\n",
    "            print(f\"  {i+1}. [{score:.3f}] {chunk['title']}\")\n",
    "            print(f\"     규칙: {chunk['main_rule']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea91119",
   "metadata": {},
   "source": [
    "### RAG 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db1f23e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiin/miniconda3/envs/k_rag/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'def main():\\n    \"\"\"메인 실행 함수\"\"\"\\n    \\n    # 기존 RAG 시스템 로드 (이미 구축되어 있다고 가정)\\n    from __main__ import rag  # 이미 만든 rag 시스템 사용\\n    \\n    # RAG 파이프라인 초기화\\n    pipeline = KoreanGrammarRAGPipeline(\\n        rag_system=rag,\\n        model_name=\"Qwen/Qwen2.5-3B-Instruct\"  # 또는 다른 한국어 모델\\n    )\\n    \\n    # 훈련 데이터 로드\\n    pipeline.load_training_data(\"/home/jiin/korean_grammar_rag/data/korean_language_rag_V1.0_train.json\")\\n    \\n    # 테스트 실행\\n    pipeline.test_on_training_data(num_samples=3)\\n    \\n    # 개별 질문 테스트\\n    print(\"\\n=== 개별 질문 테스트 ===\")\\n    test_question = \"\"가축을 기를 때에는 {먹이량/먹이양}을 조절해 주어야 한다.\" 가운데 올바른 것을 선택하고, 그 이유를 설명하세요.\"\\n    \\n    result = pipeline.process_question(test_question)\\n    print(f\"질문: {result[\\'question\\']}\")\\n    print(f\"답변: {result[\\'final_answer\\']}\")\\n\\nif __name__ == \"__main__\":\\n    main()'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from typing import List, Dict, Tuple\n",
    "import re\n",
    "\n",
    "class KoreanGrammarRAGPipeline:\n",
    "    def __init__(self, rag_system, model_name: str = \"Qwen/Qwen2.5-3B-Instruct\"):\n",
    "        \"\"\"\n",
    "        RAG 파이프라인 초기화\n",
    "        Args:\n",
    "            rag_system: 이미 구축된 SimpleKoreanRAG 시스템\n",
    "            model_name: 생성에 사용할 언어모델\n",
    "        \"\"\"\n",
    "        self.rag_system = rag_system\n",
    "        \n",
    "        print(f\"생성 모델 로드 중: {model_name}\")\n",
    "        \n",
    "        # 토크나이저와 모델 로드\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None\n",
    "        )\n",
    "        \n",
    "        # 패딩 토큰 설정\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        print(\"RAG 파이프라인 초기화 완료\")\n",
    "    \n",
    "    def load_training_data(self, train_json_path: str):\n",
    "        \"\"\"훈련 데이터 로드 및 확인\"\"\"\n",
    "        with open(train_json_path, 'r', encoding='utf-8') as f:\n",
    "            self.train_data = json.load(f)\n",
    "        \n",
    "        print(f\"훈련 데이터 로드 완료: {len(self.train_data)}개\")\n",
    "        \n",
    "        # 첫 번째 샘플 구조 확인\n",
    "        if self.train_data:\n",
    "            print(\"\\n첫 번째 훈련 샘플:\")\n",
    "            print(json.dumps(self.train_data[0], ensure_ascii=False, indent=2))\n",
    "        \n",
    "        return self.train_data\n",
    "    \n",
    "    def retrieve_relevant_chunks(self, question: str, top_k: int = 3) -> List[Dict]:\n",
    "        \"\"\"질문에 관련된 청크 검색\"\"\"\n",
    "        # RAG 시스템으로 관련 청크 검색\n",
    "        results = self.rag_system.search(question, top_k=top_k)\n",
    "        \n",
    "        # 청크만 추출 (점수 제거)\n",
    "        relevant_chunks = [chunk for chunk, score in results]\n",
    "        \n",
    "        return relevant_chunks\n",
    "    \n",
    "    def format_retrieved_context(self, chunks: List[Dict]) -> str:\n",
    "        \"\"\"검색된 청크들을 컨텍스트 문자열로 포맷팅\"\"\"\n",
    "        context_parts = []\n",
    "        \n",
    "        for i, chunk in enumerate(chunks, 1):\n",
    "            context = f\"[참고 규칙 {i}]\\n\"\n",
    "            context += f\"제목: {chunk['title']}\\n\"\n",
    "            context += f\"규칙: {chunk['main_rule']}\\n\"\n",
    "            \n",
    "            # 예시가 있으면 추가\n",
    "            if chunk.get('examples'):\n",
    "                context += f\"예시: {', '.join(chunk['examples'][:2])}\\n\"  # 처음 2개만\n",
    "            \n",
    "            # 올바른/틀린 쌍이 있으면 추가\n",
    "            if chunk.get('pairs'):\n",
    "                for pair in chunk['pairs'][:2]:  # 처음 2개만\n",
    "                    context += f\"올바른 표현: {pair.get('correct', '')}\\n\"\n",
    "                    context += f\"틀린 표현: {pair.get('wrong', '')}\\n\"\n",
    "            \n",
    "            context_parts.append(context)\n",
    "        \n",
    "        return \"\\n\".join(context_parts)\n",
    "    \n",
    "    def create_prompt(self, question: str, context: str) -> str:\n",
    "        \"\"\"질문과 컨텍스트로 프롬프트 생성\"\"\"\n",
    "        \n",
    "        # 질문 유형 파악\n",
    "        question_type = \"선택형\" if \"{\" in question and \"}\" in question else \"교정형\"\n",
    "        \n",
    "        prompt = f\"\"\"당신은 한국어 어문 규범 전문가입니다. 주어진 참고 규칙을 바탕으로 질문에 정확히 답변해주세요.\n",
    "\n",
    "참고 규칙:\n",
    "{context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변 형식: \"{{정답}}이/가 옳다. {{이유}}\"\n",
    "\n",
    "답변:\"\"\"\n",
    "        \n",
    "        return prompt\n",
    "    \n",
    "    def generate_answer(self, prompt: str, max_length: int = 300) -> str:\n",
    "        \"\"\"프롬프트로부터 답변 생성\"\"\"\n",
    "        \n",
    "        # 토크나이징\n",
    "        inputs = self.tokenizer(\n",
    "            prompt,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            max_length=1024,\n",
    "            padding=True\n",
    "        )\n",
    "        \n",
    "        # GPU로 이동\n",
    "        if torch.cuda.is_available():\n",
    "            inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "        \n",
    "        # 생성\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model.generate(\n",
    "                **inputs,\n",
    "                max_new_tokens=max_length,\n",
    "                temperature=0.7,\n",
    "                do_sample=True,\n",
    "                pad_token_id=self.tokenizer.eos_token_id,\n",
    "                eos_token_id=self.tokenizer.eos_token_id\n",
    "            )\n",
    "        \n",
    "        # 디코딩\n",
    "        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 프롬프트 부분 제거하고 답변만 추출\n",
    "        answer = generated_text[len(prompt):].strip()\n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def post_process_answer(self, answer: str) -> str:\n",
    "        \"\"\"답변 후처리 (형식 맞추기)\"\"\"\n",
    "        \n",
    "        # 불필요한 부분 제거\n",
    "        answer = answer.strip()\n",
    "        \n",
    "        # 줄바꿈을 공백으로 변경\n",
    "        answer = re.sub(r'\\n+', ' ', answer)\n",
    "        \n",
    "        # 중복 공백 제거\n",
    "        answer = re.sub(r'\\s+', ' ', answer)\n",
    "        \n",
    "        # 형식 확인 및 수정\n",
    "        if not ((\"이 옳다\" in answer) or (\"가 옳다\" in answer)):\n",
    "            # 형식이 맞지 않으면 기본 형식으로 감쌈\n",
    "            if answer:\n",
    "                answer = f\"{answer}이 옳다.\"\n",
    "        \n",
    "        return answer\n",
    "    \n",
    "    def process_question(self, question: str, retrieve_top_k: int = 3) -> Dict:\n",
    "        \"\"\"전체 RAG 프로세스 실행\"\"\"\n",
    "        \n",
    "        # 1. 관련 청크 검색\n",
    "        relevant_chunks = self.retrieve_relevant_chunks(question, top_k=retrieve_top_k)\n",
    "        \n",
    "        # 2. 컨텍스트 포맷팅\n",
    "        context = self.format_retrieved_context(relevant_chunks)\n",
    "        \n",
    "        # 3. 프롬프트 생성\n",
    "        prompt = self.create_prompt(question, context)\n",
    "        \n",
    "        # 4. 답변 생성\n",
    "        raw_answer = self.generate_answer(prompt)\n",
    "        \n",
    "        # 5. 후처리\n",
    "        final_answer = self.post_process_answer(raw_answer)\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"retrieved_chunks\": relevant_chunks,\n",
    "            \"context\": context,\n",
    "            \"prompt\": prompt,\n",
    "            \"raw_answer\": raw_answer,\n",
    "            \"final_answer\": final_answer\n",
    "        }\n",
    "    \n",
    "    def evaluate_on_sample(self, sample: Dict) -> Dict:\n",
    "        \"\"\"단일 샘플에 대한 평가\"\"\"\n",
    "        \n",
    "        question = sample[\"input\"][\"question\"]\n",
    "        ground_truth = sample[\"output\"][\"answer\"]\n",
    "        \n",
    "        # RAG 프로세스 실행\n",
    "        result = self.process_question(question)\n",
    "        \n",
    "        return {\n",
    "            \"question\": question,\n",
    "            \"ground_truth\": ground_truth,\n",
    "            \"predicted\": result[\"final_answer\"],\n",
    "            \"retrieved_chunks\": result[\"retrieved_chunks\"],\n",
    "            \"context\": result[\"context\"]\n",
    "        }\n",
    "    \n",
    "    def test_on_training_data(self, num_samples: int = 5):\n",
    "        \"\"\"훈련 데이터의 일부로 테스트\"\"\"\n",
    "        \n",
    "        if not hasattr(self, 'train_data'):\n",
    "            print(\"먼저 훈련 데이터를 로드해주세요.\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n=== {num_samples}개 샘플 테스트 ===\")\n",
    "        \n",
    "        for i in range(min(num_samples, len(self.train_data))):\n",
    "            sample = self.train_data[i]\n",
    "            result = self.evaluate_on_sample(sample)\n",
    "            \n",
    "            print(f\"\\n--- 샘플 {i+1} ---\")\n",
    "            print(f\"질문: {result['question']}\")\n",
    "            print(f\"정답: {result['ground_truth']}\")\n",
    "            print(f\"예측: {result['predicted']}\")\n",
    "            print(f\"검색된 청크 수: {len(result['retrieved_chunks'])}\")\n",
    "            \n",
    "            # 검색된 첫 번째 청크 제목만 출력\n",
    "            if result['retrieved_chunks']:\n",
    "                print(f\"가장 관련성 높은 규칙: {result['retrieved_chunks'][0]['title']}\")\n",
    "\n",
    "'''def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    \n",
    "    # 기존 RAG 시스템 로드 (이미 구축되어 있다고 가정)\n",
    "    from __main__ import rag  # 이미 만든 rag 시스템 사용\n",
    "    \n",
    "    # RAG 파이프라인 초기화\n",
    "    pipeline = KoreanGrammarRAGPipeline(\n",
    "        rag_system=rag,\n",
    "        model_name=\"Qwen/Qwen2.5-3B-Instruct\"  # 또는 다른 한국어 모델\n",
    "    )\n",
    "    \n",
    "    # 훈련 데이터 로드\n",
    "    pipeline.load_training_data(\"/home/jiin/korean_grammar_rag/data/korean_language_rag_V1.0_train.json\")\n",
    "    \n",
    "    # 테스트 실행\n",
    "    pipeline.test_on_training_data(num_samples=3)\n",
    "    \n",
    "    # 개별 질문 테스트\n",
    "    print(\"\\n=== 개별 질문 테스트 ===\")\n",
    "    test_question = \"\\\"가축을 기를 때에는 {먹이량/먹이양}을 조절해 주어야 한다.\\\" 가운데 올바른 것을 선택하고, 그 이유를 설명하세요.\"\n",
    "    \n",
    "    result = pipeline.process_question(test_question)\n",
    "    print(f\"질문: {result['question']}\")\n",
    "    print(f\"답변: {result['final_answer']}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940f6e0c",
   "metadata": {},
   "source": [
    "### Train 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fb8589a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiin/miniconda3/envs/k_rag/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'def main():\\n    \"\"\"메인 실행 함수\"\"\"\\n    \\n    # RAG 시스템 로드 (선택사항 - 컨텍스트 추가용)\\n    try:\\n        from __main__ import rag  # 기존에 만든 rag 시스템\\n        print(\"RAG 시스템을 컨텍스트 추가용으로 사용합니다.\")\\n        rag_system = rag\\n    except:\\n        print(\"RAG 시스템 없이 훈련합니다.\")\\n        rag_system = None\\n    \\n    # 트레이너 초기화\\n    trainer = KoreanGrammarTrainer(\\n        model_name=\"Qwen/Qwen2.5-3B-Instruct\",  # 또는 다른 모델\\n        rag_system=rag_system,\\n        output_dir=\"./korean_grammar_model\"\\n    )\\n    \\n    # 데이터 로드\\n    train_dataset, val_dataset = trainer.load_data(\\n        train_path=\"train.json\",\\n        val_path=\"validation.json\"  # 없으면 자동 분할\\n    )\\n    \\n    # 훈련 실행\\n    trainer.train(\\n        num_epochs=3,\\n        batch_size=2,  # RTX 4090에 맞게 조정\\n        learning_rate=5e-5\\n    )\\n    \\n    # 테스트\\n    test_questions = [\\n        \"\"가축을 기를 때에는 {먹이량/먹이양}을 조절해 주어야 한다.\" 가운데 올바른 것을 선택하고, 그 이유를 설명하세요.\",\\n        \"다음 문장에서 어문 규범에 부합하지 않는 부분을 찾아 고치고, 그렇게 고친 이유를 설명하세요. \"어서 쾌차하시길 바래요.\"\"\\n    ]\\n    \\n    trainer.test_generation(test_questions)\\n\\nif __name__ == \"__main__\":\\n    main()'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForCausalLM,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForLanguageModeling\n",
    ")\n",
    "from typing import List, Dict\n",
    "import os\n",
    "\n",
    "class KoreanGrammarDataset(Dataset):\n",
    "    \"\"\"한국어 어문 규범 데이터셋\"\"\"\n",
    "    \n",
    "    def __init__(self, data: List[Dict], tokenizer, rag_system=None, max_length: int = 512):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.rag_system = rag_system\n",
    "        self.max_length = max_length\n",
    "        \n",
    "        # 훈련용 프롬프트 생성\n",
    "        self.processed_data = self._process_data()\n",
    "    \n",
    "    def _get_relevant_context(self, question: str) -> str:\n",
    "        \"\"\"질문에 관련된 컨텍스트 검색 (RAG 시스템 사용)\"\"\"\n",
    "        if self.rag_system is None:\n",
    "            return \"\"\n",
    "        \n",
    "        try:\n",
    "            # 관련 청크 검색 (상위 2개만)\n",
    "            results = self.rag_system.search(question, top_k=2)\n",
    "            \n",
    "            context_parts = []\n",
    "            for chunk, score in results:\n",
    "                context = f\"참고: {chunk['title']} - {chunk['main_rule']}\"\n",
    "                if chunk.get('examples'):\n",
    "                    context += f\" 예시: {chunk['examples'][0]}\"\n",
    "                context_parts.append(context)\n",
    "            \n",
    "            return \" \".join(context_parts)\n",
    "        except:\n",
    "            return \"\"\n",
    "    \n",
    "    def _process_data(self):\n",
    "        \"\"\"데이터 전처리\"\"\"\n",
    "        processed = []\n",
    "        \n",
    "        for item in self.data:\n",
    "            question = item[\"input\"][\"question\"]\n",
    "            answer = item[\"output\"][\"answer\"]\n",
    "            \n",
    "            # RAG 컨텍스트 추가 (선택사항)\n",
    "            context = self._get_relevant_context(question)\n",
    "            \n",
    "            # 프롬프트 구성\n",
    "            if context:\n",
    "                prompt = f\"\"\"다음 규칙을 참고하여 질문에 답하세요.\n",
    "\n",
    "참고 규칙: {context}\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변: {answer}\"\"\"\n",
    "            else:\n",
    "                prompt = f\"\"\"한국어 어문 규범 질문에 답하세요.\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변: {answer}\"\"\"\n",
    "            \n",
    "            processed.append({\n",
    "                \"text\": prompt,\n",
    "                \"question\": question,\n",
    "                \"answer\": answer\n",
    "            })\n",
    "        \n",
    "        return processed\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.processed_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        item = self.processed_data[idx]\n",
    "        \n",
    "        # 토크나이징\n",
    "        encoding = self.tokenizer(\n",
    "            item[\"text\"],\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": encoding[\"input_ids\"].flatten()  # 언어 모델링에서는 input_ids가 labels\n",
    "        }\n",
    "\n",
    "class KoreanGrammarTrainer:\n",
    "    \"\"\"한국어 어문 규범 모델 훈련 클래스\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 model_name: str = \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "                 rag_system=None,\n",
    "                 output_dir: str = \"./korean_grammar_model\"):\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.rag_system = rag_system\n",
    "        self.output_dir = output_dir\n",
    "        \n",
    "        print(f\"모델 로드 중: {model_name}\")\n",
    "        \n",
    "        # 토크나이저 로드\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        if self.tokenizer.pad_token is None:\n",
    "            self.tokenizer.pad_token = self.tokenizer.eos_token\n",
    "        \n",
    "        # 모델 로드\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_name,\n",
    "            torch_dtype=torch.float32,  # FP32 사용으로 안정성 확보\n",
    "            device_map=\"auto\" if torch.cuda.is_available() else None,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        \n",
    "        print(\"모델 로드 완료\")\n",
    "    \n",
    "    def load_data(self, train_path: str, val_path: str = None):\n",
    "        \"\"\"훈련 및 검증 데이터 로드\"\"\"\n",
    "        print(f\"훈련 데이터 로드: {train_path}\")\n",
    "        \n",
    "        with open(train_path, 'r', encoding='utf-8') as f:\n",
    "            train_data = json.load(f)\n",
    "        \n",
    "        print(f\"훈련 데이터: {len(train_data)}개\")\n",
    "        \n",
    "        # 검증 데이터 (있으면 로드, 없으면 훈련 데이터의 20% 사용)\n",
    "        if val_path and os.path.exists(val_path):\n",
    "            with open(val_path, 'r', encoding='utf-8') as f:\n",
    "                val_data = json.load(f)\n",
    "            print(f\"검증 데이터: {len(val_data)}개\")\n",
    "        else:\n",
    "            # 훈련 데이터의 20%를 검증용으로 분할\n",
    "            split_idx = int(len(train_data) * 0.8)\n",
    "            val_data = train_data[split_idx:]\n",
    "            train_data = train_data[:split_idx]\n",
    "            print(f\"데이터 분할 - 훈련: {len(train_data)}개, 검증: {len(val_data)}개\")\n",
    "        \n",
    "        # 데이터셋 생성\n",
    "        self.train_dataset = KoreanGrammarDataset(\n",
    "            train_data, \n",
    "            self.tokenizer, \n",
    "            self.rag_system\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = KoreanGrammarDataset(\n",
    "            val_data, \n",
    "            self.tokenizer, \n",
    "            self.rag_system\n",
    "        )\n",
    "        \n",
    "        return self.train_dataset, self.val_dataset\n",
    "    \n",
    "    def setup_training_args(self, \n",
    "                           num_epochs: int = 3,\n",
    "                           batch_size: int = 4,\n",
    "                           learning_rate: float = 5e-5,\n",
    "                           warmup_steps: int = 100):\n",
    "        \"\"\"훈련 설정\"\"\"\n",
    "        \n",
    "        training_args = TrainingArguments(\n",
    "            output_dir=self.output_dir,\n",
    "            overwrite_output_dir=True,\n",
    "            \n",
    "            # 기본 설정\n",
    "            num_train_epochs=num_epochs,\n",
    "            per_device_train_batch_size=batch_size,\n",
    "            per_device_eval_batch_size=batch_size,\n",
    "            \n",
    "            # 학습률 및 옵티마이저\n",
    "            learning_rate=learning_rate,\n",
    "            warmup_steps=warmup_steps,\n",
    "            weight_decay=0.01,\n",
    "            \n",
    "            # 로깅 및 저장\n",
    "            logging_dir=f\"{self.output_dir}/logs\",\n",
    "            logging_steps=50,\n",
    "            save_steps=500,\n",
    "            save_total_limit=1,\n",
    "            \n",
    "            # 평가\n",
    "            evaluation_strategy=\"steps\",\n",
    "            eval_steps=100,\n",
    "            \n",
    "            # GPU 최적화 - FP16 비활성화\n",
    "            fp16=False,  # FP16 문제 해결을 위해 비활성화\n",
    "            bf16=False,  # BF16도 비활성화\n",
    "            dataloader_pin_memory=False,\n",
    "            \n",
    "            # 기타\n",
    "            remove_unused_columns=False,\n",
    "            report_to=None,  # wandb 등 사용 안함\n",
    "        )\n",
    "        \n",
    "        return training_args\n",
    "    \n",
    "    def train(self, \n",
    "              num_epochs: int = 3,\n",
    "              batch_size: int = 4,\n",
    "              learning_rate: float = 5e-5):\n",
    "        \"\"\"모델 훈련 실행\"\"\"\n",
    "        \n",
    "        if not hasattr(self, 'train_dataset'):\n",
    "            raise ValueError(\"먼저 데이터를 로드해주세요 (load_data 메서드 사용)\")\n",
    "        \n",
    "        print(\"훈련 시작...\")\n",
    "        \n",
    "        # 훈련 설정\n",
    "        training_args = self.setup_training_args(\n",
    "            num_epochs=num_epochs,\n",
    "            batch_size=batch_size,\n",
    "            learning_rate=learning_rate\n",
    "        )\n",
    "        \n",
    "        # 데이터 콜레이터\n",
    "        data_collator = DataCollatorForLanguageModeling(\n",
    "            tokenizer=self.tokenizer,\n",
    "            mlm=False  # 자동회귀 언어 모델링\n",
    "        )\n",
    "        \n",
    "        # 트레이너 생성\n",
    "        trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=training_args,\n",
    "            train_dataset=self.train_dataset,\n",
    "            eval_dataset=self.val_dataset,\n",
    "            data_collator=data_collator,\n",
    "            tokenizer=self.tokenizer,\n",
    "        )\n",
    "        \n",
    "        # 훈련 실행\n",
    "        trainer.train()\n",
    "        \n",
    "        # 최종 모델 저장\n",
    "        trainer.save_model(self.output_dir)\n",
    "        self.tokenizer.save_pretrained(self.output_dir)\n",
    "        \n",
    "        print(f\"훈련 완료! 모델이 {self.output_dir}에 저장되었습니다.\")\n",
    "        \n",
    "        return trainer\n",
    "    \n",
    "    def test_generation(self, test_questions: List[str]):\n",
    "        \"\"\"훈련된 모델로 생성 테스트\"\"\"\n",
    "        print(\"\\n=== 생성 테스트 ===\")\n",
    "        \n",
    "        for question in test_questions:\n",
    "            prompt = f\"\"\"한국어 어문 규범 질문에 답하세요.\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    "            \n",
    "            # 토크나이징\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "            \n",
    "            if torch.cuda.is_available():\n",
    "                inputs = {k: v.to(self.model.device) for k, v in inputs.items()}\n",
    "            \n",
    "            # 생성\n",
    "            with torch.no_grad():\n",
    "                outputs = self.model.generate(\n",
    "                    **inputs,\n",
    "                    max_new_tokens=150,\n",
    "                    temperature=0.7,\n",
    "                    do_sample=True,\n",
    "                    pad_token_id=self.tokenizer.eos_token_id\n",
    "                )\n",
    "            \n",
    "            # 디코딩\n",
    "            generated = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "            answer = generated[len(prompt):].strip()\n",
    "            \n",
    "            print(f\"\\n질문: {question}\")\n",
    "            print(f\"답변: {answer}\")\n",
    "\n",
    "'''def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    \n",
    "    # RAG 시스템 로드 (선택사항 - 컨텍스트 추가용)\n",
    "    try:\n",
    "        from __main__ import rag  # 기존에 만든 rag 시스템\n",
    "        print(\"RAG 시스템을 컨텍스트 추가용으로 사용합니다.\")\n",
    "        rag_system = rag\n",
    "    except:\n",
    "        print(\"RAG 시스템 없이 훈련합니다.\")\n",
    "        rag_system = None\n",
    "    \n",
    "    # 트레이너 초기화\n",
    "    trainer = KoreanGrammarTrainer(\n",
    "        model_name=\"Qwen/Qwen2.5-3B-Instruct\",  # 또는 다른 모델\n",
    "        rag_system=rag_system,\n",
    "        output_dir=\"./korean_grammar_model\"\n",
    "    )\n",
    "    \n",
    "    # 데이터 로드\n",
    "    train_dataset, val_dataset = trainer.load_data(\n",
    "        train_path=\"train.json\",\n",
    "        val_path=\"validation.json\"  # 없으면 자동 분할\n",
    "    )\n",
    "    \n",
    "    # 훈련 실행\n",
    "    trainer.train(\n",
    "        num_epochs=3,\n",
    "        batch_size=2,  # RTX 4090에 맞게 조정\n",
    "        learning_rate=5e-5\n",
    "    )\n",
    "    \n",
    "    # 테스트\n",
    "    test_questions = [\n",
    "        \"\\\"가축을 기를 때에는 {먹이량/먹이양}을 조절해 주어야 한다.\\\" 가운데 올바른 것을 선택하고, 그 이유를 설명하세요.\",\n",
    "        \"다음 문장에서 어문 규범에 부합하지 않는 부분을 찾아 고치고, 그렇게 고친 이유를 설명하세요. \\\"어서 쾌차하시길 바래요.\\\"\"\n",
    "    ]\n",
    "    \n",
    "    trainer.test_generation(test_questions)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9486ca59",
   "metadata": {},
   "source": [
    "## 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294a3bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RAG 시스템 만들기\n",
    "\n",
    "# 1. 먼저 SimpleKoreanRAG 시스템 생성\n",
    "rag = SimpleKoreanRAG()\n",
    "\n",
    "# 2. 청크 로드\n",
    "rag.load_chunks(\"/home/jiin/korean_grammar_rag/code/korean_grammar_chunks.json\")\n",
    "\n",
    "# 3. 임베딩 생성\n",
    "rag.create_embeddings()\n",
    "\n",
    "# 4. 벡터 저장소 구축\n",
    "rag.build_vector_store()\n",
    "\n",
    "# 5. 저장 (나중에 재사용하기 위해)\n",
    "rag.save(\"./rag_system\")\n",
    "\n",
    "print(\"RAG 시스템 구축 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c59e36b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 이제 RAG를 포함한 트레이너 생성\n",
    "trainer = KoreanGrammarTrainer(\n",
    "    model_name=\"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    rag_system=rag,  # 방금 만든 RAG 시스템\n",
    "    output_dir=\"./korean_grammar_model\"\n",
    ")\n",
    "\n",
    "# 7. 훈련 데이터 로드\n",
    "trainer.load_data(\"/home/jiin/korean_grammar_rag/data/korean_language_rag_V1.0_train.json\")\n",
    "\n",
    "# 8. 훈련 실행\n",
    "trainer.train(num_epochs=3, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40644d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_trained_model_fast(question):\n",
    "    \"\"\"빠른 추론을 위한 설정\"\"\"\n",
    "    prompt = f\"\"\"한국어 어문 규범 질문에 답하세요.\n",
    "\n",
    "질문: {question}\n",
    "\n",
    "답변:\"\"\"\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=256)  # 길이 줄임\n",
    "    \n",
    "    # GPU로 이동\n",
    "    if torch.cuda.is_available():\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "        model.cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=50,      # 토큰 수 대폭 줄임\n",
    "            temperature=0.3,        # 더 결정적으로\n",
    "            do_sample=False,        # 샘플링 끔 (greedy)\n",
    "            num_beams=1,           # 빔 서치 끄기\n",
    "            pad_token_id=tokenizer.eos_token_id,\n",
    "            eos_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    \n",
    "    generated = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    answer = generated[len(prompt):].strip()\n",
    "    \n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7235f847",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag = SimpleKoreanRAG()\n",
    "\n",
    "# 저장된 시스템 로드\n",
    "rag.load(\"./rag_system\")\n",
    "\n",
    "print(\"RAG 시스템 로드 완료!\")\n",
    "\n",
    "test_questions = [\n",
    "    \"\\\"가축을 기를 때에는 {먹이량/먹이양}을 조절해 주어야 한다.\\\" 가운데 올바른 것을 선택하고, 그 이유를 설명하세요.\",\n",
    "    \"다음 문장에서 어문 규범에 부합하지 않는 부분을 찾아 고치고, 그렇게 고친 이유를 설명하세요. \\\"어서 쾌차하시길 바래요.\\\"\",\n",
    "    \"띄어쓰기 규칙에 대해 설명하세요.\"\n",
    "]\n",
    "\n",
    "# 기존 RAG 파이프라인으로도 테스트 (비교용)\n",
    "pipeline = KoreanGrammarRAGPipeline(rag_system=rag, model_name=\"./korean_grammar_model\")\n",
    "\n",
    "print(\"\\n=== RAG 파이프라인 테스트 ===\")\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    result = pipeline.process_question(question)\n",
    "    print(f\"\\n{i}. 질문: {question}\")\n",
    "    print(f\"   답변: {result['final_answer']}\")\n",
    "    print(f\"   검색된 규칙: {result['retrieved_chunks'][0]['title'] if result['retrieved_chunks'] else 'None'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d5cff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 시스템 로드 중...\n",
      "한국어 임베딩 모델 로드 중...\n",
      "사용 디바이스: cuda\n",
      "시스템이 ./rag_system에서 로드되었습니다\n",
      "RAG 시스템 로드 완료!\n",
      "생성 모델 로드 중: ./korean_grammar_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards:  33%|███▎      | 1/3 [00:01<00:03,  1.72s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:04<00:00,  1.57s/it]\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG 파이프라인 초기화 완료\n",
      "\n",
      "1. RAG + 파인튜닝 모델 추론\n",
      "Validation 데이터 로드: /home/jiin/korean_grammar_rag/data/korean_language_rag_V1.0_dev.json\n",
      "총 127개 샘플\n",
      "추론 시작...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "추론 중:   0%|          | 0/127 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def run_inference_on_validation(rag_pipeline, val_data_path: str, output_path: str = \"validation_predictions.json\"):\n",
    "    \"\"\"\n",
    "    Validation 데이터에 RAG 파이프라인을 적용하여 예측 결과 생성\n",
    "    \n",
    "    Args:\n",
    "        rag_pipeline: KoreanGrammarRAGPipeline 인스턴스\n",
    "        val_data_path: validation 데이터 파일 경로\n",
    "        output_path: 결과 저장할 파일 경로\n",
    "    \"\"\"\n",
    "    \n",
    "    # Validation 데이터 로드\n",
    "    print(f\"Validation 데이터 로드: {val_data_path}\")\n",
    "    with open(val_data_path, 'r', encoding='utf-8') as f:\n",
    "        val_data = json.load(f)\n",
    "    \n",
    "    print(f\"총 {len(val_data)}개 샘플\")\n",
    "    \n",
    "    # 예측 결과 저장할 리스트\n",
    "    predictions = []\n",
    "    \n",
    "    # 각 샘플에 대해 추론 수행\n",
    "    print(\"추론 시작...\")\n",
    "    for sample in tqdm(val_data, desc=\"추론 중\"):\n",
    "        sample_id = sample[\"id\"]\n",
    "        question = sample[\"input\"][\"question\"]\n",
    "        \n",
    "        try:\n",
    "            # RAG 파이프라인으로 답변 생성\n",
    "            result = rag_pipeline.process_question(question)\n",
    "            predicted_answer = result['final_answer']\n",
    "            \n",
    "            # 결과 저장 (id와 output만)\n",
    "            predictions.append({\n",
    "                \"id\": sample_id,\n",
    "                \"output\": {\n",
    "                    \"answer\": predicted_answer\n",
    "                }\n",
    "            })\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"샘플 {sample_id} 추론 실패: {e}\")\n",
    "            # 실패한 경우 빈 답변\n",
    "            predictions.append({\n",
    "                \"id\": sample_id,\n",
    "                \"output\": {\n",
    "                    \"answer\": \"답변 생성 실패\"\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    # 결과 저장\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(predictions, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(f\"예측 결과가 {output_path}에 저장되었습니다.\")\n",
    "    return predictions\n",
    "\n",
    "def evaluate_with_official_metric(predictions_path: str, ground_truth_path: str):\n",
    "    \"\"\"\n",
    "    공식 평가 코드를 사용하여 성능 평가\n",
    "    \n",
    "    Args:\n",
    "        predictions_path: 예측 결과 파일 경로\n",
    "        ground_truth_path: 정답 파일 경로\n",
    "    \"\"\"\n",
    "    \n",
    "    # 예측 결과와 정답 로드\n",
    "    with open(predictions_path, 'r', encoding='utf-8') as f:\n",
    "        predictions = json.load(f)\n",
    "    \n",
    "    with open(ground_truth_path, 'r', encoding='utf-8') as f:\n",
    "        ground_truth = json.load(f)\n",
    "    \n",
    "    print(f\"예측 데이터: {len(predictions)}개\")\n",
    "    print(f\"정답 데이터: {len(ground_truth)}개\")\n",
    "    \n",
    "    # 공식 평가 함수 사용 (첨부된 코드에서)\n",
    "    try:\n",
    "        # 여기서 첨부된 evaluation 함수를 import 해야 함\n",
    "        # 파일이 같은 디렉토리에 있다고 가정\n",
    "        from evaluation_metrics import evaluation  # 첨부된 파일을 evaluation_metrics.py로 저장했다고 가정\n",
    "        \n",
    "        # 한국어 어문 규범 RAG 평가 실행\n",
    "        results = evaluation(\n",
    "            inferenced_data=predictions,\n",
    "            ground_truth=ground_truth,\n",
    "            evaluation_metrics=['korean_contest_RAG_QA'],\n",
    "            ratio=1,\n",
    "            iteration=1\n",
    "        )\n",
    "        \n",
    "        return results\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"공식 평가 코드를 찾을 수 없습니다. 수동으로 평가합니다.\")\n",
    "        return manual_evaluation(predictions, ground_truth)\n",
    "\n",
    "def manual_evaluation(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    공식 평가 코드가 없을 경우 수동 평가\n",
    "    \"\"\"\n",
    "    # ID로 매칭\n",
    "    pred_dict = {item['id']: item['output']['answer'] for item in predictions}\n",
    "    true_dict = {item['id']: item['output']['answer'] for item in ground_truth}\n",
    "    \n",
    "    # Exact Match 계산 (간단 버전)\n",
    "    exact_matches = 0\n",
    "    total = 0\n",
    "    \n",
    "    for item_id in true_dict:\n",
    "        if item_id in pred_dict:\n",
    "            true_answer = true_dict[item_id].strip()\n",
    "            pred_answer = pred_dict[item_id].strip()\n",
    "            \n",
    "            # \"{정답}이/가 옳다\" 부분 추출해서 비교\n",
    "            true_main = extract_main_answer(true_answer)\n",
    "            pred_main = extract_main_answer(pred_answer)\n",
    "            \n",
    "            if true_main == pred_main:\n",
    "                exact_matches += 1\n",
    "            \n",
    "            total += 1\n",
    "    \n",
    "    exact_match_score = exact_matches / total if total > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        \"exact_match\": exact_match_score,\n",
    "        \"exact_match_percent\": exact_match_score * 100,\n",
    "        \"total_samples\": total,\n",
    "        \"correct_samples\": exact_matches\n",
    "    }\n",
    "\n",
    "def extract_main_answer(answer_text):\n",
    "    \"\"\"답변에서 주요 정답 부분 추출\"\"\"\n",
    "    import re\n",
    "    \n",
    "    # \"{정답}이/가 옳다\" 패턴 찾기\n",
    "    patterns = [\n",
    "        r'\"([^\"]+)\"[이가]\\s*옳다',\n",
    "        r'([^.]+)[이가]\\s*옳다'\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, answer_text)\n",
    "        if match:\n",
    "            return match.group(1).strip()\n",
    "    \n",
    "    # 패턴이 없으면 첫 번째 문장 반환\n",
    "    sentences = answer_text.split('.')\n",
    "    return sentences[0].strip() if sentences else answer_text.strip()\n",
    "\n",
    "def compare_models(rag_predictions_path: str, simple_predictions_path: str, ground_truth_path: str):\n",
    "    \"\"\"\n",
    "    RAG 모델과 단순 모델 성능 비교\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"모델 성능 비교\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # RAG 모델 평가\n",
    "    print(\"\\n1. RAG + 파인튜닝 모델 평가:\")\n",
    "    rag_results = evaluate_with_official_metric(rag_predictions_path, ground_truth_path)\n",
    "    print_evaluation_results(rag_results, \"RAG + 파인튜닝\")\n",
    "    \n",
    "    # 단순 모델 평가 (있는 경우)\n",
    "    if os.path.exists(simple_predictions_path):\n",
    "        print(\"\\n2. 파인튜닝만 모델 평가:\")\n",
    "        simple_results = evaluate_with_official_metric(simple_predictions_path, ground_truth_path)\n",
    "        print_evaluation_results(simple_results, \"파인튜닝만\")\n",
    "        \n",
    "        # 성능 차이 출력\n",
    "        if 'exact_match' in rag_results and 'exact_match' in simple_results:\n",
    "            improvement = rag_results['exact_match'] - simple_results['exact_match']\n",
    "            print(f\"\\n📈 RAG 효과: {improvement:.4f} ({improvement*100:.2f}%p 개선)\")\n",
    "\n",
    "def print_evaluation_results(results, model_name):\n",
    "    \"\"\"평가 결과 출력\"\"\"\n",
    "    print(f\"\\n--- {model_name} 결과 ---\")\n",
    "    \n",
    "    if 'error' in results:\n",
    "        print(f\"❌ 오류: {results['error']}\")\n",
    "        return\n",
    "    \n",
    "    if 'exact_match' in results:\n",
    "        print(f\"Exact Match: {results['exact_match']:.4f} ({results['exact_match']*100:.2f}%)\")\n",
    "    \n",
    "    if 'rouge_1' in results:\n",
    "        print(f\"ROUGE-1: {results['rouge_1']:.4f}\")\n",
    "    \n",
    "    if 'bertscore' in results:\n",
    "        print(f\"BERTScore: {results['bertscore']:.4f}\")\n",
    "    \n",
    "    if 'bleurt' in results:\n",
    "        print(f\"BLEURT: {results['bleurt']:.4f}\")\n",
    "    \n",
    "    if 'final_score' in results:\n",
    "        print(f\"최종 점수: {results['final_score']:.4f} ({results['final_score']*100:.2f}%)\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"메인 실행 함수\"\"\"\n",
    "    \n",
    "    # RAG 시스템 로드\n",
    "    print(\"RAG 시스템 로드 중...\")\n",
    "    rag = SimpleKoreanRAG()\n",
    "    rag.load(\"./rag_system\")\n",
    "    print(\"RAG 시스템 로드 완료!\")\n",
    "    \n",
    "    # RAG 파이프라인 생성\n",
    "    pipeline = KoreanGrammarRAGPipeline(\n",
    "        rag_system=rag, \n",
    "        model_name=\"./korean_grammar_model\"\n",
    "    )\n",
    "    \n",
    "    # Validation 데이터 경로들\n",
    "    val_data_path = \"/home/jiin/korean_grammar_rag/data/korean_language_rag_V1.0_dev.json\"  # 실제 경로로 수정\n",
    "    \n",
    "    # 1. RAG 파이프라인으로 추론\n",
    "    print(\"\\n1. RAG + 파인튜닝 모델 추론\")\n",
    "    rag_predictions = run_inference_on_validation(\n",
    "        pipeline, \n",
    "        val_data_path, \n",
    "        \"rag_validation_predictions.json\"\n",
    "    )\n",
    "    \n",
    "    # 2. 평가 실행\n",
    "    print(\"\\n2. 성능 평가\")\n",
    "    results = evaluate_with_official_metric(\n",
    "        \"rag_validation_predictions.json\",\n",
    "        val_data_path\n",
    "    )\n",
    "    \n",
    "    print_evaluation_results(results, \"RAG + 파인튜닝\")\n",
    "    \n",
    "    # 3. 몇 개 샘플 결과 확인\n",
    "    print(\"\\n3. 샘플 결과 확인\")\n",
    "    show_sample_results(\"rag_validation_predictions.json\", val_data_path, num_samples=5)\n",
    "\n",
    "def show_sample_results(predictions_path: str, ground_truth_path: str, num_samples: int = 5):\n",
    "    \"\"\"몇 개 샘플의 예측 결과 확인\"\"\"\n",
    "    \n",
    "    with open(predictions_path, 'r', encoding='utf-8') as f:\n",
    "        predictions = json.load(f)\n",
    "    \n",
    "    with open(ground_truth_path, 'r', encoding='utf-8') as f:\n",
    "        ground_truth = json.load(f)\n",
    "    \n",
    "    # ID로 매칭\n",
    "    true_dict = {item['id']: item for item in ground_truth}\n",
    "    \n",
    "    print(f\"\\n{'='*50} 샘플 결과 {'='*50}\")\n",
    "    \n",
    "    for i, pred_item in enumerate(predictions[:num_samples]):\n",
    "        item_id = pred_item['id']\n",
    "        true_item = true_dict.get(item_id)\n",
    "        \n",
    "        if true_item:\n",
    "            print(f\"\\n--- 샘플 {i+1} (ID: {item_id}) ---\")\n",
    "            print(f\"질문: {true_item['input']['question'][:100]}...\")\n",
    "            print(f\"정답: {true_item['output']['answer'][:150]}...\")\n",
    "            print(f\"예측: {pred_item['output']['answer'][:150]}...\")\n",
    "            \n",
    "            # 정답 여부 확인\n",
    "            true_main = extract_main_answer(true_item['output']['answer'])\n",
    "            pred_main = extract_main_answer(pred_item['output']['answer'])\n",
    "            match_status = \"✅ 정답\" if true_main == pred_main else \"❌ 오답\"\n",
    "            print(f\"결과: {match_status}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac79389",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "k_rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
